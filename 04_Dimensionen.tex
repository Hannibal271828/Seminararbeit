\chapter{Grundlagen der Linearen Algebra}
\label{sec:LA}
Die Lineare Algebra ist eine mathematische Teildisziplin, welche u.a. Mengen mit bestimmten Eigenschaften bestehend aus Vektoren\footnote{Sie werden nicht mit Pfeilen gekennzeichnet und ihre Koordinaten werden nicht untereinander geschrieben. }, den sogenannten \aclp{VR}n, behandelt. Diese Räume bestehen aus einer Gruppe und einem Körper.\footnote{Gruppen und Körper bezeichnen Mengen mit besonderen Attributen und Rechenoprationen wie Addition und Multiplikation.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Gruppen}
\label{sec:Gruppen}

\theoremstyle{definition}
\begin{definition}\cite[S. 28]{Enzy} (\emph{Kartesisches Produkt})
{\glqq}Das kartesische Produkt $A\times B$ zweier Mengen $A$ und $B$ ist die Menge aller geordneten Paare $(a,b)$ mit $a \in A$ und $b \in B$: \[A \times B \vcentcolon= \{(a,b) \mid a \in A, b \in B\} \text{.{\grqq}}\]
\end{definition}

\begin{example}\label{kart}
In \ref{sec:KoS} haben wir von $n$-dimensionalen Koordinatensystemen gesprochen, die mehrfache kartesische Produkte von $\mathbb{R}$ sind:
\[\underbrace{\mathbb{R} \times \mathbb{R} \times ... \times \mathbb{R}}_{n\text{-mal}} \vcentcolon= \mathbb{R}^n \text{. (vgl. \cite[S. 28]{Enzy})}\]
Die Koordinaten eines Punktes oder eines Vektors im $\mathbb{R}^n$ können nicht vertauscht werden, da sie sonst ganz andere Punkte oder Vektoren repräsentieren würden.
\end{example}

\theoremstyle{definition}
\begin{definition}vgl.\,\cite[S. 19, 4.1]{Skript} (\emph{innere Verknüpfung}) Eine (innere) Verknüpfung auf einer Menge $G$ ist eine Abbildung
\[ \circ: G \times G \rightarrow G \text{.} \] 
\end{definition}

Seien $g_1, g_2 \in G$ beliebig. Das Paar $(g_1,g_2)$ aus der Definitionsmenge $\mathbb{D}=G \times G$ wird einem Element $\circ(g_1, g_2)$ aus der Wertemenge $\mathbb{W}=G$ zugeordnet.\footnote{Wir einigen uns auf die Schreibweise $g_1 \circ g_2$.} Der Kringel $\circ$ dient als eine Variable. Wir können sie durch $+$ oder $\cdot$ ersetzen. Somit erhalten wir $g_1+g_2$ oder $g_1 \cdot g_2$.
\newpage
\begin{example}{(\emph{innere Verknüpfungen mit $\mathbb{R}$})} 
\label{verk}
\begin{itemize}
\item Addition. 
\begin{align*}
+: \mathbb{R} \times \mathbb{R} &\rightarrow \mathbb{R}
\\ (a,b) &\mapsto a+b
\end{align*}
\item Multiplikation. Sei $\mathbb{R}^* \vcentcolon =\mathbb{R} \backslash \{0\}$.
\begin{align*}
\cdot: \mathbb{R}^* \times \mathbb{R}^* &\rightarrow \mathbb{R}^*
\\ (a,b) &\mapsto a \cdot b
\end{align*}
\end{itemize}
\end{example}


\theoremstyle {definition}
\begin{definition} \cite[S. 19, 4.2]{Skript} (\emph{Gruppe})
\label{Gruppe}{\glqq}Eine Gruppe ist eine Menge $G$ mit einer Verknüpfung 
\[ \circ : G \times G \rightarrow G\text{[,]}\]
für die die folgenden Eigenschaften gelten
\begin{enumerate}
	\item (Assoziativität) Für alle $x, y, z \in G$ gilt 	
	\label{(i)}
	\[(x \circ y) \circ z = x \circ (y \circ z)\text{.}\]
	\item (Existenz eines neutralen Elements) Es gibt ein $e \in G$ mit  
	\label{(ii)}	
	\[e \circ x = x = x \circ e \;{\text{für alle}}\; x \in G \text{.}\]
	\item (Existenz von Inversen) Sei $x \in G$. Dann gibt es ein $y \in G$ mit 
	\label{(iii)}	
	\[y \circ x = e = x \circ y \text{.{\grqq}}\]
\end{enumerate}
\end{definition}

\begin{definition}\label{abl.Gruppe}vgl.\,\cite[S. 19, 4.3]{Skript} (\emph{abelsche oder kommutative Gruppe}) Man bezeichnet eine Gruppe auch als kommutativ oder abelsch, wenn für alle $g_1,g_2 \in G$ gilt
\[g_1 \circ g_2 = g_2 \circ g_1 \text{.}\]
\end{definition}

\newpage
Die reellen Zahlen bilden abelsche Gruppen bezüglich der Addition und Multiplikation mit den inneren Verknüpfungen aus Beispiel \ref{verk}.

\begin{example}(\emph{reelle additive Gruppe $(\mathbb{R},+)$})
\label{rag}
Bei der Addition in $\mathbb{R}$ gelten das Assoziativ- und das Kommutativgesetz. Das neutrale Element ist die Null. Das additive Inverse einr reellen Zahl $r$ ist sein Negatives $-r$. 
\end{example}

\begin{example}(\emph{reelle multiplikative Gruppe $(\mathbb{R}^*,\cdot)$})
\label{rmg}
Die Multiplikation in $\mathbb{R}^*$ ist auch assoziativ und kommutativ. Die Eins ist das neutrale Element. Sei $s \in \mathbb{R}^*$, so ist sein Inverses der Kehrbruch $\frac{1}{s}$. Die Null ist bei $(\mathbb{R}^*,\cdot)$ ausgeschlossen, weil sie kein multiplikative Inverses besitzt, insbesondere stünde Null im Nenner.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Körper}
\label{sec:Körper}
Die Addition und Multiplikation in einer Menge können in einer gemeinsamen Struktur zusammengefasst werden.
\theoremstyle{defintion}
\begin{definition}vgl.\,\cite{Koerper} (\emph{Körper})
\label{Koerper}
Ein Körper\footnote{Körperelemente werden in dieser Arbeit mit griechischen Buchstaben gekennzeichnet.} besteht aus zwei Mengen $K$ und $K^*=K \backslash \{0\}$ mit zwei Verknüpfungen
\begin{align*}
	+&: K \times K \rightarrow K
	\\ \cdot &: K^* \times K^* \rightarrow K^*
\end{align*}

für die gelten:
\begin{enumerate}
\item $(K,+)$ ist eine abelsche Gruppe mit $e=0$ als das neutrale Element.
\item $(K^*,\cdot)$ ist eine kommutative Gruppe mit dem $e=1$ als das neutrale Element.
\item(Distrivbutivgesetze)
Für alle $\alpha, \beta, \gamma \in K$ gilt
\begin{align*}
\alpha \cdot (\beta+\gamma )  &= \alpha \cdot \beta + \alpha \cdot \gamma 
\\ (\alpha+\beta) \cdot \gamma  &= \alpha \cdot \gamma  + \beta \cdot \gamma\text{.}
\end{align*}
\end{enumerate}
\end{definition}


\theoremstyle{example}
\begin{example}
Die Menge $\mathbb{R}$ bildet einen Körper mit der additiven Gruppe $(\mathbb{R},+)$ und der multiplikativen Gruppe $(\mathbb{R}^*,\cdot)$ und den Distributivgesetzen.\footnote{Es sei angemerkt, dass $\mathbb{Q}$ und die komplexen Zahlen $\mathbb{C}$ ebenso eine Körperstruktur besitzen.}
\end{example}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Vektorräume}
\label{sec:VR}
Wollen wir Punkte aus dem $\mathbb{R}^2$ oder $\mathbb{R}^3$ verschieben, brauchen wir einen Vektor, der mit einem Anderen addiert und mit einem Skalar multipliziert, also gestreckt oder gestaucht, werden kann. 


\begin{definition}vgl.\,\cite[S. 28, 6.1]{Skript} (\emph{Vektorraum}) \label{VR-axiome}Ein \acl{VR} über den Körper $K$ ($K$-Vektorraum) beinhaltet die abelsche additive Gruppe $(V,+)$ und die Skalarmultiplikation mit der äußeren Verknüpfung 
	\begin{align*}
	\cdot : K \times V &\rightarrow V
	\\ (\lambda,v) &\mapsto \lambda \cdot v\text{.}
	\end{align*}
Es müssen folgende Eigenschaften für alle $\lambda, \lambda_1, \lambda_2 \in K$ und $v, v_1, v_2 \in V$ gelten:
	\begin{enumerate}
		\item $(\lambda_1 + \lambda_2) \cdot v = \lambda_1 \cdot v + 	\lambda_2 \cdot v $
		\item $ \lambda \cdot (v_1 + v_2) = \lambda \cdot v_1 + \lambda \cdot v_2$
		\item $\lambda_1 \cdot (\lambda_2 \cdot v) = (\lambda_1 \cdot \lambda_2) \cdot v$
		\item $ 1 \cdot v = v$.{\grqq}
	\end{enumerate}
\end{definition}


Vektorräume haben zwei verschiedene Additionen und Multiplikationen. Zum einen gibt es die Körperaddition und -multiplikation, zum Anderen die Vektorraumaddition und die Skalarmultiplikation \(\lambda \cdot v \) für $\lambda \in K$ und $v \in V$ (vgl. \cite[S. 28, 6.1]{Skript}).
\newpage Wir wollen im folgenden die Vektoraddition und Skalarmultiplikation auf die $n$-dimensionalen Vektoren des $\mathbb{R}$-\acl{VR} $\mathbb{R}^n$ aus Beispiel \ref{kart} übertragen.
  
\begin{definition}vgl.\,\cite[S. 28, 6.2]{Skript} (\emph{$n$-faches kartesisches Produkt als $\mathbb{R}$-Vektorraum}) Wir machen 
\[ \mathbb{R}^n = \{(\chi_1,...,\chi_n) \mid \chi_1,...,\chi_n \in \mathbb{R}\}\]
zu einem $\mathbb{R}$-Vektorraum mit folgender Definition von komponentenweisen Vektoraddition
\[(\chi_1,...,\chi_n)+(\psi_1,...,\psi_n) \vcentcolon= (\chi_1 + \psi_1,\chi_2 + \psi_2,..., \chi_n + \psi_n)\]
und Skalarmultiplikation
\[\lambda \cdot (\chi_1,...,\chi_n)\vcentcolon= (\lambda \cdot \chi_1,...,\lambda \cdot \chi_n)\text{.}\]
\end{definition}
Mit diesen Definitionen kann man mit $n$-dimensionalen Vektoren ähnlich wie mit zwei- und dreidimensionalen rechnen. %So kann man sich höherdimensionale Vektoren $formal$ vorstellen.

\begin{definition}vgl.\,\cite[S. 298]{Tut} (\emph{Untervektorraum})\label{UVR} Wir nennen eine nichtleere Teilmenge $U \subset V$ \acl{UVR}, falls gilt 
\begin{enumerate}
\item  $\textbf{0} \in U$ (Nullvektor in $U$)
\item $u,v \in U \Rightarrow u + v \in U$ (Abgeschlossenheit\footnote{Werden beliebige Elemente einer Menge $M$ verknüpft und ist das Resultat ebenso ein Element aus $M$, so ist die Verknüpfung abgeschlossen.} bzgl. Vektoraddition)
\item $u \in U \text{,} \; \lambda \in K \Rightarrow \lambda \cdot u \in U$ (Abgeschlossenheit bzgl. Skalarmultiplikation)
\end{enumerate} 
\end{definition}
%Zitat aus S.298 Tut.

\begin{example}
Jede Ebene oder Gerade des $\mathbb{R}^3$, die durch den Ursprung geht, ist ein \acl{UVR}, zum Beispiel die $x_1x_2$-, $x_1x_3$- und $x_2x_3$-Ebene. Ist eine Ebene jedoch nach oben oder unten verschoben und enthält somit nicht den Nullvektor $\textbf{0}$, spricht man von einem affinen \acl{UVR}. 
\end{example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{\aclp{EZS}}
\label{Erz}
Die Menge der Summen von mehreren gestauchten und gestreckten $n$-dimensionalen Vektoren werden im Folgenden näher betrachtet. 

\begin{definition}vgl.\,\cite[S. 298, 16.3]{Tut} (\emph{\acl{Linkomb}}) Sei $K$ ein Körper, $V$ ein $K$-\acl{VR} und ${v_1,...,v_n \in V}$. Ein Vektor $v \in V$ lässt sich mit $v_1,...,v_n$ und den Koeffizienten $\lambda_i \in K$ für $i=1,...,n$ und wie folgt linear kombinieren:
\[v = \sum_{i=1}^n \lambda_i v_i = \lambda_1 v_1 + \lambda_2 v_2 + \lambda_3 v_3 + ... + \lambda_n v_n \text{.}\]
\end{definition}
%indir Zitat aus tutorium S.298 Def.16.3

\begin{example}
In der Abbildung \ref{linkombgrafik} wird die Linearkombination der Vektoren $v_1$ und $v_2$ ersichtlich.
 
\end{example}
\begin{figure}[h]
\centering
\def\svgwidth{150pt}
\input{Bilder/Linkomb.pdf_tex}
\caption{\(\sum \limits_{i=1}^{2} \lambda_i v_i = \lambda_1 v_1 + \lambda_2 v_2\Rightarrow\lambda_1=\lambda_2=3\)}
\label{linkombgrafik}
\end{figure}

\newpage
\begin{definition}\cite[S. 30, 1.5]{Bosch} (\emph{lineare Hülle}) Sei $V$ ein Vektorraum über den Körper $K$ und $H \subset V$. Die Menge aller \aclp{Linkomb} 
\[\langle H \rangle_K \vcentcolon= \{ \sum \limits_{i=1}^{n} \lambda_i h_i \mid \lambda_i \in K, h_i \in H \, \text{für} \, i = 1,...,n \} \]
bezeichnen wir als die "lineare Hülle" \cite[S. 298, 16.4]{Tut}, das "Erzeugnis" \cite[S. 298, 16.4]{Tut} oder den "Span" \cite[S. 298, 16.4]{Tut} von $H$. 
%indir Zit. aus Bosch S.30 
\label{linhuelledef}
\end{definition}

\begin{figure} [htbp]
 	\centering
	\begin{minipage}[b]{0.4\textwidth}
		\def\svgwidth{175pt}
		\input{Bilder/LinHuelle.pdf_tex}
		\caption{$\langle v \rangle_\mathbb{R} \in \mathbb{R}^2$} 
		\label{fig:UVR}
	\end{minipage}
\hfill
	\begin{minipage}[b]{0.4\textwidth}
		\def\svgwidth{175pt}
		\input{Bilder/2dKoS.pdf_tex}
		\caption{\( \langle e_1,e_2 \rangle_{\mathbb{R}} = \mathbb{R}^2\).}
		\label{fig:EZS}
	\end{minipage}
\end{figure} 
Im Falle der Abbildung \ref{fig:UVR} ist das Erzeugnis von $v$ eine Gerade, die durch den Ursprung geht, also ein \acl{UVR} von $\acl{R2}$. Die Vektoren $e_1$ und $e_2$ aus der Abbildung \ref{fig:EZS} spannen den gesamten $\mathbb{R}^2$ auf, da jeder beliebige Vektor aus ihnen kombiniert werden kann.
 
\begin{definition}\cite[S. 39, 9.4]{Skript} (\emph{\acl{EZS}}) "Eine Teilmenge $M$ eines $K$-Vektorraums $V$ heißt \acl{EZS} von $V$, wenn $V = \langle M \rangle_K$. $V$ heißt endlich erzeugt von $M$, wenn es ein endliches\footnote{Die minimale Anzahl an Vektoren, die $V$ erzeugt, ist endlich.} \acl{EZS} gibt."
\end{definition}

\begin{example}
Die Abbildung \ref{fig:EZS} beschreibt ein endliches Erzeugendensystem, da die Teilmenge $E=\{e_1, e_2\} \subset \mathbb{R}^2$ endlich ist und den $\mathbb{R}^2$ erzeugt. Würden wir noch weitere Vektoren zu $E$ hinzufügen, wäre es dennoch ein \acl{EZS}, weil sein Erzeugnis immer noch $\mathbb{R}^2$ bleibt. Entnehmen wir dagegen einen Vektor aus $E$, spannt der übrig gebliebene die $x$- bzw. $y$-Achse auf.  
\end{example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\theoremstyle{definition}
\begin{definition}vgl.\, \cite[S. 298, 16.5]{Tut} ({\emph{\acl{Linunab}}}) \label{def:linunab} Seien $K$ ein Körper, $V$ ein $K$-\acl{VR} und $v_1, ..., v_n \in V$. Wie nennen das System \((v_1, ..., v_n)\) \acl{linunab}, wenn gilt
	\begin{align}\sum \limits_{i=1}^{n} \lambda_i v_i = 0 \Longrightarrow \lambda_i = 0 \; \text{für alle}\; i=1,...,n \text{.}\label{lin}\end{align}
	Andernfalls heißt \( (v_1, ..., v_n)\) \acl{linab}.
\end{definition}

Sei eine Menge \acl{linunab} und sei dies zu überprüfen. So ist die Gleichung (\ref{lin}) nur durch die {\glqq}trivial[e]{\grqq} \cite[S. 307, 16.5]{Tut} Lösung, also alle Koeffizienten $\lambda_i = 0$, lösbar.
Sei dagegeben eine Menge \acl{linab} und sei dies zu überprüfen, dann ist mindestens ein $\lambda_i\not= 0$.

\begin{example}
Ein zu $v$ aus der Abbildung \ref{fig:UVR} linear abhängiger Vektor $w_a$ ist $w_a\in \langle v \rangle$; für einen linear unabhängigen $w_u$ dagegen gilt $w_u \notin \langle v \rangle$. Diese Aussage gilt nicht nur für zwei- oder dreidimensionale Vektoren, sondern auch für $n$-dimensionale. 
\end{example}

\begin{example}
\label{lu}
Wir wollen berechnen, ob die Vektoren aus Abbildung \ref{fig:EZS} \acl{linunab} sind.
\[\sum \limits_{i=1}^{2} \lambda_i e_1=0\]
\[ \lambda_1 \cdot (1,0) + \lambda_2 \cdot (0,1) = 0\]
Gleichungssystem aufstellen:
\begin{align*}
\lambda_1 \cdot 1 + \lambda_2 \cdot 0 &= 0
\\ \lambda_1 \cdot 0 + \lambda_2 \cdot 1 &= 0
\\ \Rightarrow \lambda_1, \lambda_2= 0
\end{align*} 
Die Gleichung ist nur mit der trivialen Lösung lösbar. Damit sind $e_1$ und $e_2$ \acl{linunab}.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Basis und Dimension}
\label{sec:Basis}
Die aus dem Kapitel \ref{Erz} erläuterten Begrifflichkeiten werden sehr wichtig sein, um die Basis, eine grundlegende Voraussetzung zur Definition des Dimensionenbegriffs, zu erklären.


\begin{theo}\cite[S. 41, 9.16]{Skript} \label{theo:Basis}(\emph{Basis}) \glqq Sei $V$ ein $K$-\acl{VR}. Eine Teilmenge $B \subseteq V$ heißt Basis von $V$, wenn die folgenden äquivalenten Bedingungen gelten:
		\begin{enumerate}
		\item \label{Basis1} $B$ ist ein \acl{EZS} und \acl{linunab}.
		\item \label{Basis2}$B$ ist [ein] minimales\footnote{Diese Eigenschaft gilt nicht mehr, wenn ein Element aus $B$ entfernt wird.} \acl{EZS}.
		\item \label{Basis3}$B$ ist [eine] maximale\footnote{Wird ein $v \in V$ zu $B$ hinzugefügt, so ist $B$ nicht mehr \acl{linunab}.} \acl{linunab}e Teilmenge.{\grqq}
		\end{enumerate}
\end{theo}

Um das Theorem bestehend aus der Äquivalenzaussage (i) $\Leftrightarrow$ (ii) $\Leftrightarrow$ (iii) zu zeigen, reicht es den Beweis des sogenannten Ringschlusses für die Implikationen (i) $\Rightarrow$ (ii), (ii) $\Rightarrow$ (iii) und (iii) $\Rightarrow$ (i) zu führen. Wir verwenden im Folgenden ausschließlich Widerspruchsbeweise. Die Widersprüche zu den fettgedruckten Voraussetzungen werden zur Vereinfachung unterstrichen.

\begin{proof}  
Vor.: Sei $B = \{\acl{vs}\}$. $B$ ist \acl{EZS} und \textbf{\acl{linunab}}.
\\ Beh.: (i) $\Rightarrow$ (ii) 
\\ Bew.  vgl. \cite[S. 41, 9.16 (a) $\Rightarrow$ (b)]{Skript}: \acl{ang} $B$ ist nicht minimal. Dann ist $B$ ohne $v_k$ für $k=1,...,n$ immer noch ein \acl{EZS}:
\\ Sei $\lambda_i \in K$ für $i=1,...,n$.
\begin{align*}\Rightarrow v_k = \sum \limits_{\substack{i=1\\i\not=k}}^{n}\lambda_i v_i
\Leftrightarrow 0 = \sum \limits_{\substack{i=1\\i\not=k}}^{n}\lambda_i v_i - v_k 
\end{align*}
\(\Rightarrow \lambda_k \not= 0 \Rightarrow \text{\underline{linear abhängig}} \, \lightning
\Rightarrow \text{Beh.} \)
\\In Wortform: Der Nullvektor erhält somit eine nichttriviale Darstellung, da $\lambda_k=1\not=0$. Insbesondere ist das System $B$ mit $v_k$ für $k=1,...,n$ \underline{linear abhängig}, was ein Widerspruch zu der Voraussetzung der linearen Unabhängigkeit ist, woraus folgt, dass die Behauptung wahr ist.
\newpage
\noindent Vor.: B ist ein \textbf{minimales \text{\acl{EZS}}}.
\\ Beh.: (ii) $\Rightarrow$ (iii) 
\\ Bew. vgl. \cite[S. 41, 9.16 (b) $\Rightarrow$ (c)]{Skript}: Zuerst zeigen wir, dass $B$ \acl{linunab} ist.
\\ Angenommen $B$ ist \acl{linab}. Sei \(\lambda_i \; \text{für} \; i=1,...,n\). Dann hat die Gleichung \(\acl{Summe}=0\) mindestens ein $\lambda_i\not=0$ mit $i=1,...,n$ als Lösung.
\\Wir nehmen o.B.d.A\footnote{Ohne Beschränkung der Allgmeinheit. Wir schauen uns einfachheitshalber einen Spezialfall an, um die Aussage im Allgemeinen zu beweisen. Die anderen Fälle würden analog zu zeigen sein.} an:
Sei $\lambda_j \not= 0$ für $j \in {1,...,n}$. $B$ ist linear abhängig wegen $v_j$. 
\begin{align*}
&\Rightarrow \lambda_j v_j + \sum\limits_{\substack{i=1\\i\not=j}}^{n} \lambda_i v_i = 0
\\ &\Leftrightarrow \lambda_j v_j = - \sum\limits_{\substack{i=1\\i\not=j}}^{n} \lambda_i v_i
\\ &\Leftrightarrow v_j = - \sum\limits_{\substack{i=1\\i\not=j}}^{n} \frac{\lambda_i}{\lambda_j} v_i \in\, \langle B\, \backslash \{v_j\}\rangle_K
\end{align*}
Der Vektor $v_j$ liegt in $\langle B \, \backslash \, \{v_j\} \rangle$. Wir benötigen, um den Widerspruch zu erhalten, einen Zwischenbeweis, der aussagt, dass die Menge $B \, \backslash \, \{v_j\}$ entgegen der Minimalität ein \acl{EZS} von $V$ ist.
\par
\begingroup
\leftskip=2cm
\noindent
\\Zw.vor.: $v_j \in B \, \backslash \, \{v_j\}$, also $ \{v_j\}\, \cup\, B \, \backslash \, \{v_j\}$ \textbf{linear abhängig}. 
\\Zw.beh.: $B \, \backslash \, \{v_j\}$ ist ein \acl{EZS} von $V$.
\\Zw.bew.: Angenommen, $B \, \backslash \, \{v_j\}$ sei kein \acl{EZS}. Dann gibt es ein $v_j \notin B \, \backslash \, \{v_j\}$. Daraus folgt allerdings: Die Menge $B \, \backslash \, \{v_j\} \,\cup\, \{v_j\} = B\, \cup\, \{v_j\} $ ist \underline{\acl{linunab}}, was der Voraussetzung, dass $B \,\cup\, \{v_j\}$ \acl{linab} ist, widerspricht.
\\
\par
\endgroup
\noindent Daher ist \underline{$B \, \backslash \, \{v_j\}$ ein \acl{EZS}}, was im Gegensatz zu der Minimalität des \acl{EZS}s von $B$ steht. Also ist $B$ linear unabhängig.
\\ \\ \indent Es ist noch zu zeigen, dass $B$ \emph{maximal} \acl{linunab} ist. 
\\Angenommen, $B$ ist keine maximal \acl{linunab}e Teilmenge.
Dann gibt es ein $v \in V$, sodass \( B \,\cup\, \{v\}\,\text{\acl{linunab} ist}\) {\textendash} \underline{$v$ wäre nicht im Span von $B$} {\textendash}, aber $B$ erzeugt laut Voraussetzung alle Vektoren in $V$, somit gilt $v \in \langle B \rangle$, was der Widerspruch ist. Daraus folgt, dass $B$ \emph{maximal} \acl{linunab} ist. 

\newpage
\noindent Vor.: B ist eine \textbf{\text{maximale} \acl{linunab}e Teilmenge}.
\\ Beh.: (iii) $\Rightarrow$ (i) 
\\ Bew.: Es sind zwei Tatsachen zu zeigen, zum einen dass aus (iii) die lineare Unabhängigkeit von $B$ folgt, was offensichtlich aus der Voraussetzung folgt, und zum anderen dass $B$ ein \acl{EZS} ist. 
\\ Angenommen, $B$ ist kein \acl{EZS}. Dann gibt es ein $v \in V$, sodass $v \notin \langle B \rangle$ gilt, also nicht im Erzeugnis von $B$ liegt. Daraus folgt, dass \underline{$\{v\} \cup B$ linear unabhängig} ist, was der Maximalität von $B$ widerspricht. (vgl. \cite[S. 59]{Beutel}) 
\end{proof}

\begin{example} \label{basis}
Im Beispiel \ref{lu} haben wir bereits gezeigt, dass $E$ ein linear unabhängiges System ist. Um zu beweisen, dass es eine Basis ist, müssen wir noch überprüfen, ob $e_1$ und $e_2$ ein \acl{EZS} bildet.
\\ Sei $v\in \mathbb{R}^2$ beliebig. 
\[v=\lambda_1\cdot(1,0)+\lambda_2\cdot (0,1)\\
\Rightarrow v=(\lambda_1,\lambda_2)\]
Die Teilmenge $E$ erzeugt $\mathbb{R}^2$, d.h. jeder Vektor $v \in \mathbb{R}^2$ kann durch $E$ linear kombiniert werden. Somit ist sie eine Basis.
\end{example}

\theoremstyle{definition}
\begin{definition}\cite[S. 504]{Enzy} (\emph{Dimension eines \acl{VR}s}) \label{def:dim}"Ist $B$ eine Basis eines endlich erzeugten \acl{VR}s $V$, so nennt man $n \vcentcolon= |B| \in \mathbb{N}_0$ die Dimension von $V$. Wir schreiben dafür $\dim(V)= n$. Ist $V$ nicht endlich erzeugt, so setzen wir $\dim(V)\vcentcolon= \infty$." 
\end{definition}

\begin{example}
Aus dem Matheunterricht wissen wir, dass $\mathbb{R}^2$ die Dimension zwei besitzt. Lediglich haben wir diese Tatsache nie bewiesen. Im Beispiel \ref{basis} haben wir gezeigt, dass $E$ eine Basis ist:
\[|E|=2\Rightarrow\dim(E)=2\]
\end{example}

Um die Dimension eines \acl{VR} zu bestimmen, braucht man nur eine Basis zu finden und dessen Mächtigkeit zu bestimmen. Anhand dieser Vorgehensweise haben wir eine Möglichkeit entwickelt sich abstrakte, unvorstellbare Tatsachen auf Papier zu bringen, sich \emph{formal} vorzustellen. Mit dem erlernten Wissen dieses Kapitel kann eine präzisiere Beschreibung der Linearen Algebra verliehen werden: Sie ist eine mathematische Teildisziplin, welche $n$/endlich-dimensionale \aclp{VR} untersucht. 